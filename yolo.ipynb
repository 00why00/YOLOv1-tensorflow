{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YOLO-v1\n",
    "## Keras Tensorflow2.4 实现\n",
    "## 使用 VOC2007 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 train\n",
      "2007 val\n",
      "2007 test\n"
     ]
    }
   ],
   "source": [
    "# 将 xml 文件 转化为 label 形式 并保存在 txt 文件中\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Build Annotations.')\n",
    "parser.add_argument('dir', default='..', help='Annotations.')\n",
    "\n",
    "sets = [('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
    "\n",
    "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
    "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
    "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
    "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "\n",
    "\n",
    "def convert_annotation(year, image_id, f):\n",
    "    in_file = os.path.join('VOCdevkit/VOC%s/Annotations/%s.xml' % (year, image_id))\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        classes = list(classes_num.keys())\n",
    "        if cls not in classes or int(difficult) == 1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text),\n",
    "             int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
    "        f.write(' ' + ','.join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "\n",
    "for year, image_set in sets:\n",
    "    print(year, image_set)\n",
    "    with open(os.path.join('VOCdevkit/VOC%s/ImageSets/Main/%s.txt' % (year, image_set)), 'r') as f:\n",
    "        image_ids = f.read().strip().split()\n",
    "    with open(os.path.join(\"VOCdevkit\", '%s_%s.txt' % (year, image_set)), 'w') as f:\n",
    "        for image_id in image_ids:\n",
    "            f.write('%s/VOC%s/JPEGImages/%s.jpg' % (\"VOCdevkit\", year, image_id))\n",
    "            convert_annotation(year, image_id, f)\n",
    "            f.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 准备训练数据 输入448*448*3 输出7*7*30\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def read(image_path, label):\n",
    "    image = cv.imread(image_path)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image_h, image_w = image.shape[0:2]\n",
    "    image = cv.resize(image, (448, 448))\n",
    "    image = image / 255.\n",
    "\n",
    "    label_matrix = np.zeros([7, 7, 30])\n",
    "    for l in label:\n",
    "        l = l.split(',')\n",
    "        l = np.array(l, dtype=np.int)\n",
    "        xmin = l[0]\n",
    "        ymin = l[1]\n",
    "        xmax = l[2]\n",
    "        ymax = l[3]\n",
    "        cls = l[4]\n",
    "        x = (xmin + xmax) / 2 / image_w\n",
    "        y = (ymin + ymax) / 2 / image_h\n",
    "        w = (xmax - xmin) / image_w\n",
    "        h = (ymax - ymin) / image_h\n",
    "        loc = [7 * x, 7 * y]\n",
    "        loc_i = int(loc[1])\n",
    "        loc_j = int(loc[0])\n",
    "        y = loc[1] - loc_i\n",
    "        x = loc[0] - loc_j\n",
    "\n",
    "        if label_matrix[loc_i, loc_j, 24] == 0:\n",
    "            label_matrix[loc_i, loc_j, cls] = 1\n",
    "            label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
    "            label_matrix[loc_i, loc_j, 24] = 1  # response\n",
    "\n",
    "    return image, label_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-e52a611d35b9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'YOLO V1'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mwhile\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwaitKey\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m27\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdestroyAllWindows\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 检验数据是否正确 随便绘制一个数据的 image 和 label\n",
    "image_path = \"./VOCdevkit/VOC2007/JPEGImages/000207.jpg\"\n",
    "label = \"1,205,113,320,5\"\n",
    "l = label.split(',')\n",
    "l = np.array(l, dtype=np.int)\n",
    "img = cv.imread(image_path)\n",
    "ptLeftTop = (l[0], l[1])\n",
    "ptRightBottom = (l[2], l[3])\n",
    "point_color = (0, 255, 0) # BGR\n",
    "thickness = 1\n",
    "lineType = 4\n",
    "cv.rectangle(img, ptLeftTop, ptRightBottom, point_color, thickness, lineType)\n",
    "cv.namedWindow(\"YOLO V1\")\n",
    "cv.imshow('YOLO V1', img)\n",
    "while 1:\n",
    "    if cv.waitKey(0) == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 生成一个 batch size 的训练集和验证集\n",
    "from tensorflow import keras\n",
    "\n",
    "class MyGenerator(keras.utils.Sequence) :\n",
    "    def __init__(self, images, labels, batch_size) :\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param images: 全部图片\n",
    "        :param labels: 全部 label\n",
    "        :param batch_size: batch size\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __len__(self) :\n",
    "        \"\"\"\n",
    "        :return: batch 的个数\n",
    "        \"\"\"\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        \"\"\"\n",
    "        得到一个 batch size 的 image 和 label\n",
    "        :param idx: index\n",
    "        :return: image 和 label\n",
    "        \"\"\"\n",
    "        batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        train_image = []\n",
    "        train_label = []\n",
    "\n",
    "        for i in range(0, len(batch_x)):\n",
    "            img_path = batch_x[i]\n",
    "            label = batch_y[i]\n",
    "            image, label_matrix = read(img_path, label)\n",
    "            train_image.append(image)\n",
    "            train_label.append(label_matrix)\n",
    "        return np.array(train_image), np.array(train_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 准备训练集和验证集的 输入和输出数组\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "\n",
    "with open(os.path.join(\"VOCdevkit\", '2007_train.txt'), 'r') as f:\n",
    "    train_datasets = train_datasets + f.readlines()\n",
    "with open(os.path.join(\"VOCdevkit\", '2007_val.txt'), 'r') as f:\n",
    "    val_datasets = val_datasets + f.readlines()\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for item in train_datasets:\n",
    "    item = item.replace(\"\\n\", \"\").split(\" \")\n",
    "    X_train.append(item[0])\n",
    "    arr = []\n",
    "    for i in range(1, len(item)):\n",
    "        arr.append(item[i])\n",
    "    Y_train.append(arr)\n",
    "\n",
    "for item in val_datasets:\n",
    "    item = item.replace(\"\\n\", \"\").split(\" \")\n",
    "    X_val.append(item[0])\n",
    "    arr = []\n",
    "    for i in range(1, len(item)):\n",
    "        arr.append(item[i])\n",
    "    Y_val.append(arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCdevkit/VOC2007/JPEGImages/000012.jpg\n",
      "['156,97,351,270,6']\n",
      "VOCdevkit/VOC2007/JPEGImages/000005.jpg\n",
      "['263,211,324,339,8', '165,264,253,372,8', '241,194,295,299,8']\n"
     ]
    }
   ],
   "source": [
    "# 查看输入数据\n",
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "print(X_val[0])\n",
    "print(Y_val[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 448, 448, 3)\n",
      "(4, 7, 7, 30)\n",
      "(4, 448, 448, 3)\n",
      "(4, 7, 7, 30)\n"
     ]
    }
   ],
   "source": [
    "# 为训练集和验证集初始化生成器实例\n",
    "batch_size = 4\n",
    "my_training_batch_generator = MyGenerator(X_train, Y_train, batch_size)\n",
    "\n",
    "my_validation_batch_generator = MyGenerator(X_val, Y_val, batch_size)\n",
    "\n",
    "x_train, y_train = my_training_batch_generator.__getitem__(0)\n",
    "x_val, y_val = my_training_batch_generator.__getitem__(0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# YOLO 输出层\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class YoloOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_shape):\n",
    "        \"\"\"\n",
    "        :param target_shape: 输出维度\n",
    "        \"\"\"\n",
    "        super(YoloOutput, self).__init__()\n",
    "        self.target_shape = tuple(target_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        :return: 配置\n",
    "        \"\"\"\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'target_shape': self.target_shape\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # 网格大小 7 * 7\n",
    "        S = [self.target_shape[0], self.target_shape[1]]\n",
    "        # 类别数量\n",
    "        C = 20\n",
    "        # 每个格子预测的 bounding box 数量\n",
    "        B = 2\n",
    "\n",
    "        idx1 = S[0] * S[1] * C\n",
    "        idx2 = idx1 + S[0] * S[1] * B\n",
    "\n",
    "        # 类概率\n",
    "        class_prob = K.reshape(inputs[:, :idx1], (K.shape(inputs)[0],) + tuple([S[0], S[1], C]))\n",
    "        class_prob = K.softmax(class_prob)\n",
    "\n",
    "        # 置信度\n",
    "        confidence = K.reshape(inputs[:, idx1:idx2], (K.shape(inputs)[0],) + tuple([S[0], S[1], B]))\n",
    "        confidence = K.sigmoid(confidence)\n",
    "\n",
    "        # boxes\n",
    "        boxes = K.reshape(inputs[:, idx2:], (K.shape(inputs)[0],) + tuple([S[0], S[1], B * 4]))\n",
    "        boxes = K.sigmoid(boxes)\n",
    "\n",
    "        outputs = K.concatenate([class_prob, confidence, boxes])\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 448, 448, 64)      9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 224, 224, 192)     110784    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 192)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 112, 112, 128)     24704     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 112, 112, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 112, 112, 256)     65792     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 112, 112, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 56, 56, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 56, 56, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 56, 56, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 56, 56, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 56, 56, 512)       262656    \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 28, 28, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 28, 28, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 28, 28, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 28, 28, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 14, 14, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 12, 12, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 10, 10, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 102400)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               52429312  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1470)              1506750   \n",
      "_________________________________________________________________\n",
      "yolo_output (YoloOutput)     (None, 7, 7, 30)          0         \n",
      "=================================================================\n",
      "Total params: 114,617,342\n",
      "Trainable params: 114,617,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOLO 网络\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
    "\n",
    "nb_boxes=1\n",
    "grid_w=7\n",
    "grid_h=7\n",
    "cell_w=64\n",
    "cell_h=64\n",
    "img_w=grid_w*cell_w\n",
    "img_h=grid_h*cell_h\n",
    "\n",
    "model = Sequential()\n",
    "# 第一层\n",
    "model.add(Conv2D(filters=64, kernel_size= (7, 7), strides=(1, 1), input_shape =(img_h, img_w, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "# 第二层\n",
    "model.add(Conv2D(filters=192, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "# 第三层\n",
    "model.add(Conv2D(filters=128, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=256, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "# 第四层\n",
    "model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=256, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same'))\n",
    "# 第五层\n",
    "model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=512, kernel_size= (1, 1), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), padding = 'same', activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), strides=(2, 2), padding = 'same'))\n",
    "# 第六层\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "model.add(Conv2D(filters=1024, kernel_size= (3, 3), activation=lrelu, kernel_regularizer=l2(5e-4)))\n",
    "# 第七层\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1470, activation='sigmoid'))\n",
    "model.add(YoloOutput(target_shape=(7,7,30)))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    学习率类\n",
    "    \"\"\"\n",
    "    def __init__(self, schedule):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param schedule: 一个以 index 和 当前学习率 的元组作为输入，以一个 新的学习率 作为输出的函数\n",
    "        \"\"\"\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # 从优化器中得到当前学习率\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # 使用 schedule 函数得到新的学习率\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # 在 epoch 开始前设置新的学习率\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_lr))\n",
    "\n",
    "# (epoch 次数, 学习率) 元组\n",
    "LR_SCHEDULE = [\n",
    "    (0, 0.01),\n",
    "    (75, 0.001),\n",
    "    (105, 0.0001),\n",
    "]\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"\n",
    "    根据 epoch 返回对应的学习率\n",
    "    \"\"\"\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算损失\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def xywh2minmax(xy, wh):\n",
    "    \"\"\"\n",
    "    根据 label(x, y, w, h) 得到边界\n",
    "    :param xy: 中心点\n",
    "    :param wh: 长宽\n",
    "    :return: 边界\n",
    "    \"\"\"\n",
    "    xy_min = xy - wh / 2\n",
    "    xy_max = xy + wh / 2\n",
    "\n",
    "    return xy_min, xy_max\n",
    "\n",
    "\n",
    "def iou(pred_mins, pred_maxes, true_mins, true_maxes):\n",
    "    \"\"\"\n",
    "    计算 IOU\n",
    "    :param pred_mins: 预测框左坐标\n",
    "    :param pred_maxes: 预测框右坐标\n",
    "    :param true_mins: 实际框左坐标\n",
    "    :param true_maxes: 实际框右坐标\n",
    "    :return: IOU\n",
    "    \"\"\"\n",
    "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    pred_wh = pred_maxes - pred_mins\n",
    "    true_wh = true_maxes - true_mins\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = intersect_areas / union_areas\n",
    "\n",
    "    return iou_scores\n",
    "\n",
    "\n",
    "def yolo_head(feats):\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    box_xy = (feats[..., :2] + conv_index) / conv_dims * 448\n",
    "    box_wh = feats[..., 2:4] * 448\n",
    "\n",
    "    return box_xy, box_wh\n",
    "\n",
    "\n",
    "def yolo_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    损失函数\n",
    "    :param y_true: 实际值\n",
    "    :param y_pred: 预测值\n",
    "    :return: 损失\n",
    "    \"\"\"\n",
    "    label_class = y_true[..., :20]  # ? * 7 * 7 * 20\n",
    "    label_box = y_true[..., 20:24]  # ? * 7 * 7 * 4\n",
    "    response_mask = y_true[..., 24]  # ? * 7 * 7\n",
    "    response_mask = K.expand_dims(response_mask)  # ? * 7 * 7 * 1\n",
    "\n",
    "    predict_class = y_pred[..., :20]  # ? * 7 * 7 * 20\n",
    "    predict_trust = y_pred[..., 20:22]  # ? * 7 * 7 * 2\n",
    "    predict_box = y_pred[..., 22:]  # ? * 7 * 7 * 8\n",
    "\n",
    "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
    "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
    "\n",
    "    label_xy, label_wh = yolo_head(_label_box)  # ? * 7 * 7 * 1 * 2, ? * 7 * 7 * 1 * 2\n",
    "    label_xy = K.expand_dims(label_xy, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
    "    label_wh = K.expand_dims(label_wh, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
    "    label_xy_min, label_xy_max = xywh2minmax(label_xy, label_wh)  # ? * 7 * 7 * 1 * 1 * 2, ? * 7 * 7 * 1 * 1 * 2\n",
    "\n",
    "    predict_xy, predict_wh = yolo_head(_predict_box)  # ? * 7 * 7 * 2 * 2, ? * 7 * 7 * 2 * 2\n",
    "    predict_xy = K.expand_dims(predict_xy, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
    "    predict_wh = K.expand_dims(predict_wh, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
    "    predict_xy_min, predict_xy_max = xywh2minmax(predict_xy, predict_wh)  # ? * 7 * 7 * 2 * 1 * 2, ? * 7 * 7 * 2 * 1 * 2\n",
    "\n",
    "    iou_scores = iou(predict_xy_min, predict_xy_max, label_xy_min, label_xy_max)  # ? * 7 * 7 * 2 * 1\n",
    "    best_iou = K.max(iou_scores, axis=4)  # ? * 7 * 7 * 2\n",
    "    best_box = K.max(best_iou, axis=3, keepdims=True)  # ? * 7 * 7 * 1\n",
    "\n",
    "    box_mask = K.cast(best_iou >= best_box, K.dtype(best_iou))  # ? * 7 * 7 * 2\n",
    "\n",
    "    no_object_loss = 0.5 * (1 - box_mask * response_mask) * K.square(0 - predict_trust)\n",
    "    object_loss = box_mask * response_mask * K.square(1 - predict_trust)\n",
    "    confidence_loss = no_object_loss + object_loss\n",
    "    confidence_loss = K.sum(confidence_loss)\n",
    "\n",
    "    class_loss = response_mask * K.square(label_class - predict_class)\n",
    "    class_loss = K.sum(class_loss)\n",
    "\n",
    "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
    "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
    "\n",
    "    label_xy, label_wh = yolo_head(_label_box)  # ? * 7 * 7 * 1 * 2, ? * 7 * 7 * 1 * 2\n",
    "    predict_xy, predict_wh = yolo_head(_predict_box)  # ? * 7 * 7 * 2 * 2, ? * 7 * 7 * 2 * 2\n",
    "\n",
    "    box_mask = K.expand_dims(box_mask)\n",
    "    response_mask = K.expand_dims(response_mask)\n",
    "\n",
    "    box_loss = 5 * box_mask * response_mask * K.square((label_xy - predict_xy) / 448)\n",
    "    box_loss += 5 * box_mask * response_mask * K.square((K.sqrt(label_wh) - K.sqrt(predict_wh)) / 448)\n",
    "    box_loss = K.sum(box_loss)\n",
    "\n",
    "    loss = confidence_loss + class_loss + box_loss\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 完成模型\n",
    "model.compile(loss=yolo_loss ,optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model.fit(x=my_training_batch_generator,\n",
    "          steps_per_epoch = int(len(X_train) // batch_size),\n",
    "          epochs = 135,\n",
    "          verbose = 1,\n",
    "          workers= 4,\n",
    "          validation_data = my_validation_batch_generator,\n",
    "          validation_steps = int(len(X_val) // batch_size),\n",
    "          callbacks=[\n",
    "              CustomLearningRateScheduler(lr_schedule),\n",
    "              mcp_save\n",
    "          ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}